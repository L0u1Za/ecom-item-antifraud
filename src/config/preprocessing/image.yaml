# @package preprocessing.image

fast_mode: false  # Enable ultra-fast processing
enable_clip: true  # Disable CLIP for speed
enable_resnet: true  # Disable ResNet for speed
compute_clip_similarity: true  # Skip text-image similarity

# Only extract lightweight features
extract_quality_features: true  # Basic image properties (fast)
extract_hashes: true  # Perceptual hashes (fast)
extract_embeddings: true  # Skip heavy embeddings

# Batch processing settings
batch_size: 256  # Large batches for speed
num_workers: 4  # Parallel processing

# Skip expensive computations
skip_consistency_features: false
skip_duplicate_detection: false  # Keep this for fraud detection
skip_cross_seller_analysis: false

size: [224, 224]
mean: [0.485, 0.456, 0.406]
std: [0.229, 0.224, 0.225]
use_precomputed_features: true
precomputed_features_path: "data/image_features.pkl"

# Image feature extraction settings
extract_features: true
# Image directories are now taken from experiment config
features_output_dir: "data"

# Feature extraction models
models:
  clip_model: "ViT-B/32"
  resnet_model: "resnet50"

# Quality thresholds
quality_thresholds:
  min_resolution: 100
  max_compression_ratio: 0.1
  min_blurriness: 100
  duplicate_hash_distance: 5

augmentations:
  # Order matters! Start with geometric transforms, then color/intensity
  - transform:
      _target_: torchvision.transforms.RandomResizedCrop
      size: 224
      scale: [0.8, 1.0]  # Less aggressive cropping for fraud detection
    probability: 0.2
    
  - transform:
      _target_: torchvision.transforms.RandomHorizontalFlip
      p: 0.5
    probability: 0.1
    
  - transform:
      _target_: torchvision.transforms.RandomRotation
      degrees: 10  # Small rotations to preserve text readability
    probability: 0.2
    
  - transform:
      _target_: torchvision.transforms.ColorJitter
      brightness: 0.1
      contrast: 0.1
      saturation: 0.1
      hue: 0.05  # Smaller hue changes to preserve brand colors
    probability: 0.1